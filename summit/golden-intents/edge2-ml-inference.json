{
  "id": "intent-edge2-ml-001",
  "name": "ML Inference Service",
  "description": "Deploy ML inference workload at Edge Site 2",
  "serviceType": "5G-URLLC-AI",
  "target": {
    "site": "edge2",
    "cluster": "edge-cluster-2",
    "namespace": "ml-inference"
  },
  "expectations": [
    {
      "type": "ServiceCapacity",
      "targets": {
        "throughput": "1Gbps",
        "latency": "5ms",
        "availability": "99.99%"
      }
    },
    {
      "type": "ResourceAllocation",
      "targets": {
        "cpu": "8cores",
        "memory": "16Gi",
        "gpu": "1"
      }
    }
  ],
  "priority": "critical",
  "metadata": {
    "createdAt": "2025-09-25T06:00:00Z",
    "createdBy": "summit-demo",
    "tags": ["ml", "edge2", "inference", "gpu"]
  }
}
