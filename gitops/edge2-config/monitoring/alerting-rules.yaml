apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: monitoring
data:
  edge2-alerts.yml: |
    groups:
      - name: edge2-slo-alerts
        interval: 30s
        rules:
          - alert: HighErrorRate
            expr: |
              (
                sum(rate(http_requests_total{status=~"5..",site="edge2"}[5m]))
                /
                sum(rate(http_requests_total{site="edge2"}[5m]))
              ) > 0.05
            for: 2m
            labels:
              severity: warning
              site: edge2
              component: api
            annotations:
              summary: "High error rate detected on Edge2"
              description: "Error rate is {{ $value | humanizePercentage }} for the last 5 minutes"

          - alert: HighLatency
            expr: |
              histogram_quantile(0.95,
                sum(rate(http_request_duration_seconds_bucket{site="edge2"}[5m])) by (le)
              ) > 1.0
            for: 5m
            labels:
              severity: warning
              site: edge2
              component: api
            annotations:
              summary: "High latency detected on Edge2"
              description: "95th percentile latency is {{ $value }}s"

          - alert: NodeDown
            expr: up{job="kubernetes-nodes",site="edge2"} == 0
            for: 1m
            labels:
              severity: critical
              site: edge2
              component: infrastructure
            annotations:
              summary: "Node {{ $labels.node }} is down"
              description: "Kubernetes node {{ $labels.node }} has been down for more than 1 minute"

          - alert: PodCrashLooping
            expr: |
              rate(kube_pod_container_status_restarts_total{namespace=~"oran-.*"}[5m]) > 0
            for: 5m
            labels:
              severity: warning
              site: edge2
              component: workload
            annotations:
              summary: "Pod {{ $labels.pod }} is crash looping"
              description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is crash looping"

          - alert: O2IMSUnavailable
            expr: up{job="slo-metrics",site="edge2"} == 0
            for: 2m
            labels:
              severity: critical
              site: edge2
              component: o2ims
            annotations:
              summary: "O2IMS service is unavailable on Edge2"
              description: "Cannot reach O2IMS metrics endpoint for more than 2 minutes"

      - name: edge2-resource-alerts
        interval: 30s
        rules:
          - alert: HighMemoryUsage
            expr: |
              (
                sum(container_memory_working_set_bytes{site="edge2"}) by (node)
                /
                sum(kube_node_status_capacity{resource="memory",site="edge2"}) by (node)
              ) > 0.85
            for: 5m
            labels:
              severity: warning
              site: edge2
              component: infrastructure
            annotations:
              summary: "High memory usage on node {{ $labels.node }}"
              description: "Memory usage is {{ $value | humanizePercentage }} on node {{ $labels.node }}"

          - alert: HighCPUUsage
            expr: |
              (
                1 - avg(rate(node_cpu_seconds_total{mode="idle",site="edge2"}[5m])) by (node)
              ) > 0.85
            for: 5m
            labels:
              severity: warning
              site: edge2
              component: infrastructure
            annotations:
              summary: "High CPU usage on node {{ $labels.node }}"
              description: "CPU usage is {{ $value | humanizePercentage }} on node {{ $labels.node }}"