#!/bin/bash
# VM-1 2025 å¹´æœ€ä½³å¯¦è¸éƒ¨ç½²è…³æœ¬ - ä¸€éµå„ªåŒ–è…³æœ¬
# /home/ubuntu/nephio-intent-to-o2-demo/scripts/vm1-optimization/optimize_vm1_2025.sh

set -euo pipefail

readonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
readonly PROJECT_ROOT="/home/ubuntu/nephio-intent-to-o2-demo"
readonly VM1_CONFIG_DIR="$PROJECT_ROOT/vm1-2025-config"
readonly MONITORING_NAMESPACE="monitoring"
readonly GITOPS_NAMESPACE="config-management-system"
readonly LOG_FILE="$PROJECT_ROOT/artifacts/vm1-optimization-$(date +%Y%m%d-%H%M%S).log"

# æ—¥èªŒå‡½æ•¸
log() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') [INFO] $*" | tee -a "$LOG_FILE"
}

log_error() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') [ERROR] $*" | tee -a "$LOG_FILE" >&2
}

# å‰µå»ºæ—¥èªŒç›®éŒ„
mkdir -p "$(dirname "$LOG_FILE")"

# å‰µå»º 2025 å¹´æ¨™æº–ç›®éŒ„çµæ§‹
create_2025_structure() {
    log "å‰µå»º 2025 å¹´æ¨™æº–é…ç½®çµæ§‹..."

    mkdir -p "$VM1_CONFIG_DIR"/{otel,monitoring,gitops,security,o2ims}
    mkdir -p "$PROJECT_ROOT/vm1-components"
    mkdir -p "$PROJECT_ROOT/vm1-gitops-structure/platform"
    mkdir -p "$PROJECT_ROOT/vm1-monitoring"
    mkdir -p "$PROJECT_ROOT/vm1-security"

    # ç¢ºä¿ kubectl å¯ç”¨
    if ! command -v kubectl &> /dev/null; then
        log_error "kubectl æœªå®‰è£æˆ–ä¸åœ¨ PATH ä¸­"
        return 1
    fi

    log "âœ… 2025 å¹´æ¨™æº–é…ç½®çµæ§‹å‰µå»ºå®Œæˆ"
}

# æª¢æŸ¥å‰ç½®æ¢ä»¶
check_prerequisites() {
    log "æª¢æŸ¥å‰ç½®æ¢ä»¶..."

    # æª¢æŸ¥ Kubernetes é€£æ¥
    if ! kubectl cluster-info &>/dev/null; then
        log_error "ç„¡æ³•é€£æ¥åˆ° Kubernetes é›†ç¾¤"
        return 1
    fi

    # æª¢æŸ¥å¿…è¦çš„å‘½åç©ºé–“
    kubectl create namespace "$MONITORING_NAMESPACE" --dry-run=client -o yaml | kubectl apply -f -

    # æª¢æŸ¥ç¶²è·¯é€£é€šæ€§åˆ° VM-4
    if ! curl -s --max-time 5 http://172.16.4.176:30090/health &>/dev/null; then
        log "WARNING: ç„¡æ³•é€£æ¥åˆ° VM-4 Edge2 (172.16.4.176:30090)ï¼Œå°‡åœ¨ç¨å¾Œé‡è©¦"
    fi

    log "âœ… å‰ç½®æ¢ä»¶æª¢æŸ¥å®Œæˆ"
}

# å‰µå»º OpenTelemetry Collector é…ç½®
create_otel_config() {
    log "å‰µå»º OpenTelemetry Collector é…ç½®..."

    cat > "$PROJECT_ROOT/vm1-components/otel-collector.yaml" << 'EOF'
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
  namespace: monitoring
data:
  otel-collector.yaml: |
    receivers:
      prometheus:
        config:
          scrape_configs:
          - job_name: 'edge2-slo'
            static_configs:
            - targets: ['172.16.4.176:30090']
              labels:
                site: 'edge2'
                cluster: 'vm-4-edge2'
          - job_name: 'edge1-slo'
            static_configs:
            - targets: ['172.16.4.45:30090']
              labels:
                site: 'edge1'
                cluster: 'vm-2-edge1'

      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318

    processors:
      batch:
      memory_limiter:
        limit_mib: 512

      # 2025 æœ€ä½³å¯¦è¸: èªç¾©ç´„å®š
      resource:
        attributes:
        - key: deployment.environment
          value: "production"
          action: upsert
        - key: service.namespace
          value: "nephio-multi-site"
          action: upsert

    exporters:
      prometheus:
        endpoint: "0.0.0.0:8889"
        enable_open_metrics: true
        # 2025 æœ€ä½³å¯¦è¸: å–®ä½å‘½å
        add_metric_suffixes: true

      jaeger:
        endpoint: jaeger-collector:14250
        tls:
          insecure: true

    service:
      pipelines:
        metrics:
          receivers: [prometheus, otlp]
          processors: [memory_limiter, resource, batch]
          exporters: [prometheus]
        traces:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [jaeger]

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: monitoring
spec:
  replicas: 2  # é«˜å¯ç”¨
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:0.104.0
        command:
        - "/otelcol-contrib"
        - "--config=/etc/otel-collector-config/otel-collector.yaml"
        volumeMounts:
        - name: otel-collector-config-vol
          mountPath: /etc/otel-collector-config
        ports:
        - containerPort: 8889  # Prometheus metrics
        - containerPort: 4317  # OTLP gRPC
        - containerPort: 4318  # OTLP HTTP
        resources:
          requests:
            memory: 256Mi
            cpu: 100m
          limits:
            memory: 512Mi
            cpu: 500m
      volumes:
      - name: otel-collector-config-vol
        configMap:
          name: otel-collector-config

---
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  namespace: monitoring
spec:
  selector:
    app: otel-collector
  ports:
  - name: prometheus
    port: 8889
    targetPort: 8889
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
  - name: otlp-http
    port: 4318
    targetPort: 4318
EOF

    log "âœ… OpenTelemetry Collector é…ç½®å‰µå»ºå®Œæˆ"
}

# å‰µå»º GitOps æœ€ä½³å¯¦è¸é…ç½®
create_gitops_config() {
    log "å‰µå»º GitOps æœ€ä½³å¯¦è¸é…ç½®..."

    cat > "$PROJECT_ROOT/vm1-gitops-structure/platform/fleet-config.yaml" << 'EOF'
# 2025 æœ€ä½³å¯¦è¸: Fleet-wide configuration
apiVersion: configmanagement.gke.io/v1
kind: ClusterSelector
metadata:
  name: nephio-fleet
spec:
  matchLabels:
    environment: "production"
    deployment: "nephio"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nephio-fleet-config
  namespace: config-management-system
data:
  sites.yaml: |
    edge_sites:
      edge1:
        endpoint: "172.16.4.45:30090"
        cluster_type: "edge"
        region: "region-1"
      edge2:
        endpoint: "172.16.4.176:30090"
        cluster_type: "edge"
        region: "region-1"
    smo_sites:
      smo1:
        endpoint: "172.16.0.78:8080"
        cluster_type: "management"
        region: "central"
EOF

    cat > "$PROJECT_ROOT/vm1-gitops-structure/platform/kpt-functions.yaml" << 'EOF'
apiVersion: kpt.dev/v1
kind: Kptfile
metadata:
  name: nephio-platform
pipeline:
  mutators:
  - image: gcr.io/kpt-fn/set-labels:v0.2.0
    configMap:
      managed-by: "nephio-gitops"
      deployment-date: "2025-09-13"
  validators:
  - image: gcr.io/kpt-fn/kubeval:v0.3.0
  - image: gcr.io/kpt-fn/gatekeeper:v0.2.1
    configMap:
      violations: true
EOF

    log "âœ… GitOps æœ€ä½³å¯¦è¸é…ç½®å‰µå»ºå®Œæˆ"
}

# å‰µå»ºå¤šé›†ç¾¤ç›£æ§é…ç½®
create_monitoring_config() {
    log "å‰µå»ºå¤šé›†ç¾¤ç›£æ§é…ç½®..."

    cat > "$PROJECT_ROOT/vm1-monitoring/multi-cluster-slo.yaml" << 'EOF'
apiVersion: v1
kind: ConfigMap
metadata:
  name: multi-cluster-slo-config
  namespace: monitoring
data:
  slo-definitions.yaml: |
    # 2025 SLO æ¨™æº–å®šç¾©
    slos:
      edge2_availability:
        service: "edge2-slo-endpoint"
        target: 99.5
        window: "30d"
        burn_rate_alerts:
          - severity: "critical"
            burn_rate: 14.4
            window: "1h"
          - severity: "warning"
            burn_rate: 6
            window: "6h"

      edge2_latency:
        service: "edge2-slo-endpoint"
        target: 95  # 95% of requests < 15ms
        threshold: "15ms"
        window: "30d"

      cross_site_connectivity:
        service: "vm1-to-edge2"
        target: 99.9
        window: "24h"

---
# 2025 æœ€ä½³å¯¦è¸: eBPF ç¶²è·¯ç›£æ§
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: ebpf-network-monitor
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: ebpf-network-monitor
  template:
    metadata:
      labels:
        app: ebpf-network-monitor
    spec:
      hostNetwork: true
      hostPID: true
      containers:
      - name: ebpf-exporter
        image: cloudflare/ebpf_exporter:v2.3.0
        securityContext:
          privileged: true
        volumeMounts:
        - name: proc
          mountPath: /host/proc
          readOnly: true
        - name: sys
          mountPath: /host/sys
          readOnly: true
        resources:
          requests:
            memory: 128Mi
            cpu: 50m
          limits:
            memory: 256Mi
            cpu: 200m
      volumes:
      - name: proc
        hostPath:
          path: /proc
      - name: sys
        hostPath:
          path: /sys
EOF

    log "âœ… å¤šé›†ç¾¤ç›£æ§é…ç½®å‰µå»ºå®Œæˆ"
}

# éƒ¨ç½² OpenTelemetry Collector
deploy_otel_collector() {
    log "éƒ¨ç½² OpenTelemetry Collector..."

    if kubectl apply -f "$PROJECT_ROOT/vm1-components/otel-collector.yaml"; then
        # ç­‰å¾…éƒ¨ç½²å°±ç·’
        kubectl wait --for=condition=available --timeout=300s deployment/otel-collector -n "$MONITORING_NAMESPACE" || {
            log_error "OpenTelemetry Collector éƒ¨ç½²è¶…æ™‚"
            return 1
        }
        log "âœ… OpenTelemetry Collector éƒ¨ç½²æˆåŠŸ"
    else
        log_error "OpenTelemetry Collector éƒ¨ç½²å¤±æ•—"
        return 1
    fi
}

# éƒ¨ç½²å¤šé›†ç¾¤ç›£æ§
deploy_monitoring() {
    log "éƒ¨ç½²å¤šé›†ç¾¤ç›£æ§..."

    if kubectl apply -f "$PROJECT_ROOT/vm1-monitoring/multi-cluster-slo.yaml"; then
        log "âœ… å¤šé›†ç¾¤ç›£æ§é…ç½®éƒ¨ç½²æˆåŠŸ"
    else
        log_error "å¤šé›†ç¾¤ç›£æ§é…ç½®éƒ¨ç½²å¤±æ•—"
        return 1
    fi
}

# åŸ·è¡Œæ•´åˆæ¸¬è©¦
run_integration_tests() {
    log "åŸ·è¡Œæ•´åˆæ¸¬è©¦..."

    # æ¸¬è©¦ OpenTelemetry Collector å¥åº·ç‹€æ…‹
    if kubectl get pods -n "$MONITORING_NAMESPACE" -l app=otel-collector --field-selector=status.phase=Running | grep -q otel-collector; then
        log "âœ… OpenTelemetry Collector é‹è¡Œæ­£å¸¸"
    else
        log_error "OpenTelemetry Collector æœªæ­£å¸¸é‹è¡Œ"
        return 1
    fi

    # æ¸¬è©¦æŒ‡æ¨™ç«¯é»
    local otel_pod=$(kubectl get pods -n "$MONITORING_NAMESPACE" -l app=otel-collector -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
    if [[ -n "$otel_pod" ]]; then
        if kubectl port-forward -n "$MONITORING_NAMESPACE" "pod/$otel_pod" 8889:8889 &
        local pf_pid=$!
        sleep 5

        if curl -s --max-time 10 http://localhost:8889/metrics | grep -q "otelcol"; then
            log "âœ… OpenTelemetry æŒ‡æ¨™ç«¯é»æ­£å¸¸"
        else
            log "WARNING: OpenTelemetry æŒ‡æ¨™ç«¯é»å¯èƒ½æœ‰å•é¡Œ"
        fi

        kill $pf_pid 2>/dev/null || true
        fi
    fi

    log "âœ… æ•´åˆæ¸¬è©¦å®Œæˆ"
}

# ä¸»è¦åŸ·è¡Œå‡½æ•¸
main() {
    log "ğŸš€ é–‹å§‹ VM-1 2025 å¹´æœ€ä½³å¯¦è¸ä¸€éµå„ªåŒ–..."

    create_2025_structure
    check_prerequisites
    create_otel_config
    create_gitops_config
    create_monitoring_config
    deploy_otel_collector
    deploy_monitoring
    run_integration_tests

    log "âœ… VM-1 2025 å¹´æœ€ä½³å¯¦è¸ä¸€éµå„ªåŒ–å®Œæˆï¼"
    log "ğŸ“„ è©³ç´°æ—¥èªŒå·²ä¿å­˜åˆ°: $LOG_FILE"

    # åŸ·è¡Œå…¶ä»–å„ªåŒ–è…³æœ¬
    log "ğŸ”„ åŸ·è¡Œå…¶ä»–å„ªåŒ–çµ„ä»¶..."

    if [[ -x "$SCRIPT_DIR/deploy_opentelemetry_collector.sh" ]]; then
        log "åŸ·è¡Œ OpenTelemetry Collector æ·±åº¦é…ç½®..."
        "$SCRIPT_DIR/deploy_opentelemetry_collector.sh" || log "WARNING: OpenTelemetry æ·±åº¦é…ç½®å¯èƒ½æœ‰å•é¡Œ"
    fi

    if [[ -x "$SCRIPT_DIR/setup_zerotrust_policies.sh" ]]; then
        log "åŸ·è¡Œé›¶ä¿¡ä»»ç­–ç•¥é…ç½®..."
        "$SCRIPT_DIR/setup_zerotrust_policies.sh" || log "WARNING: é›¶ä¿¡ä»»ç­–ç•¥é…ç½®å¯èƒ½æœ‰å•é¡Œ"
    fi

    log "ğŸ‰ æ‰€æœ‰å„ªåŒ–å®Œæˆï¼å»ºè­°åŸ·è¡Œ postcheck é©—è­‰"
    log "å»ºè­°åŸ·è¡Œ: $PROJECT_ROOT/scripts/postcheck.sh"
}

# éŒ¯èª¤è™•ç†
trap 'log_error "è…³æœ¬åŸ·è¡Œå¤±æ•—ï¼ŒæŸ¥çœ‹æ—¥èªŒ: $LOG_FILE"' ERR

main "$@"