apiVersion: v1
kind: ConfigMap
metadata:
  name: slo-collector-script
  namespace: slo-monitoring
data:
  slo-collector.py: |
    #!/usr/bin/env python3
    import json
    import time
    import threading
    import os
    from http.server import HTTPServer, BaseHTTPRequestHandler
    from datetime import datetime
    from collections import deque

    class SLOCollector:
        def __init__(self):
            self.metrics_history = deque(maxlen=100)
            self.current_metrics = self.default_metrics()
            self.lock = threading.Lock()
            self.load_existing_metrics()

        def default_metrics(self):
            return {
                "timestamp": datetime.utcnow().isoformat() + "Z",
                "service": "echo-service-v2",
                "metrics": {
                    "total_requests": 0,
                    "success_rate": 100.0,
                    "requests_per_second": 0.0,
                    "latency_p50_ms": 0.0,
                    "latency_p95_ms": 0.0,
                    "latency_p99_ms": 0.0
                },
                "test_duration_seconds": 0,
                "concurrent_workers": 0,
                "status": "initializing"
            }

        def load_existing_metrics(self):
            metrics_file = "/data/slo-metrics.json"
            if os.path.exists(metrics_file):
                try:
                    with open(metrics_file, 'r') as f:
                        self.current_metrics = json.load(f)
                        print(f"Loaded existing metrics from {metrics_file}")
                except Exception as e:
                    print(f"Error loading metrics: {e}")

        def update_metrics(self, new_metrics):
            with self.lock:
                self.current_metrics = new_metrics
                self.current_metrics["timestamp"] = datetime.utcnow().isoformat() + "Z"
                self.current_metrics["status"] = "updated"
                self.metrics_history.append(self.current_metrics.copy())

                # Persist to disk
                try:
                    with open("/data/slo-metrics.json", 'w') as f:
                        json.dump(self.current_metrics, f, indent=2)
                except Exception as e:
                    print(f"Error saving metrics: {e}")

        def get_metrics(self):
            with self.lock:
                return self.current_metrics.copy()

        def get_history(self):
            with self.lock:
                return list(self.metrics_history)

    collector = SLOCollector()

    class SLOHandler(BaseHTTPRequestHandler):
        def do_GET(self):
            if self.path == '/metrics' or self.path == '/metrics/api/v1/slo':
                self.send_response(200)
                self.send_header('Content-type', 'application/json')
                self.send_header('Access-Control-Allow-Origin', '*')
                self.end_headers()
                metrics = collector.get_metrics()
                self.wfile.write(json.dumps(metrics, indent=2).encode())
            elif self.path == '/metrics/history':
                self.send_response(200)
                self.send_header('Content-type', 'application/json')
                self.send_header('Access-Control-Allow-Origin', '*')
                self.end_headers()
                history = collector.get_history()
                self.wfile.write(json.dumps(history, indent=2).encode())
            elif self.path == '/health':
                self.send_response(200)
                self.send_header('Content-type', 'text/plain')
                self.end_headers()
                self.wfile.write(b'OK')
            else:
                self.send_response(404)
                self.end_headers()

        def do_POST(self):
            if self.path == '/metrics':
                content_length = int(self.headers['Content-Length'])
                post_data = self.rfile.read(content_length)
                try:
                    new_metrics = json.loads(post_data.decode())
                    collector.update_metrics(new_metrics)
                    self.send_response(200)
                    self.send_header('Content-type', 'application/json')
                    self.end_headers()
                    self.wfile.write(json.dumps({"status": "success"}).encode())
                except Exception as e:
                    self.send_response(400)
                    self.send_header('Content-type', 'application/json')
                    self.end_headers()
                    self.wfile.write(json.dumps({"error": str(e)}).encode())
            else:
                self.send_response(404)
                self.end_headers()

        def log_message(self, format, *args):
            return  # Suppress access logs

    if __name__ == '__main__':
        # Simulate initial metrics
        initial_metrics = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "service": "echo-service-v2",
            "metrics": {
                "total_requests": 1000,
                "success_rate": 99.5,
                "requests_per_second": 33.3,
                "latency_p50_ms": 12.5,
                "latency_p95_ms": 45.2,
                "latency_p99_ms": 78.9
            },
            "test_duration_seconds": 30,
            "concurrent_workers": 10,
            "status": "ready"
        }
        collector.update_metrics(initial_metrics)

        server = HTTPServer(('0.0.0.0', 8090), SLOHandler)
        print('SLO Collector running on port 8090')
        print('Endpoints:')
        print('  GET  /metrics           - Current SLO metrics')
        print('  GET  /metrics/api/v1/slo - Current SLO metrics (alias)')
        print('  GET  /metrics/history   - Historical metrics')
        print('  POST /metrics           - Update metrics')
        print('  GET  /health            - Health check')
        server.serve_forever()
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: slo-data-pvc
  namespace: slo-monitoring
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: slo-collector
  namespace: slo-monitoring
  labels:
    app: slo-collector
spec:
  replicas: 1
  selector:
    matchLabels:
      app: slo-collector
  template:
    metadata:
      labels:
        app: slo-collector
    spec:
      containers:
      - name: collector
        image: python:3.9-slim
        command: ["python3", "/app/slo-collector.py"]
        ports:
        - containerPort: 8090
          name: metrics
        volumeMounts:
        - name: collector-script
          mountPath: /app
        - name: data
          mountPath: /data
        resources:
          requests:
            cpu: 50m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
        readinessProbe:
          httpGet:
            path: /health
            port: 8090
          initialDelaySeconds: 5
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /health
            port: 8090
          initialDelaySeconds: 10
          periodSeconds: 30
        env:
        - name: PYTHONUNBUFFERED
          value: "1"
      volumes:
      - name: collector-script
        configMap:
          name: slo-collector-script
          defaultMode: 0755
      - name: data
        persistentVolumeClaim:
          claimName: slo-data-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: slo-collector
  namespace: slo-monitoring
  labels:
    app: slo-collector
spec:
  type: NodePort
  ports:
  - port: 8090
    targetPort: 8090
    nodePort: 30090
    protocol: TCP
    name: metrics
  selector:
    app: slo-collector